
## 帧为什么采用『YUV』格式？
- 在达到最大压缩率的情况下，能够保证对人眼感知的失真度最小。『YUV』的三通道中，其中"Y"表示明亮度（Lumina nce或Luma），也就是灰阶值；而"U"和"V"表示的则是色度（Chrominance或Chroma）。有一堆科学家研究发现，人眼对UV的敏感度最低，因此可以极大比例地压缩UV两个通道的数值。见视频编解码学习一 yuv格式。
- 为了向前兼容黑白电视。这个就涉及历史原因了，笔者非常推荐零基础入门音视频开发。历史上在制定视频帧格式时，是有人提出过用RGB的，最终决定用YUV的真正原因其实是这个（见影像使用YUV格式，為什麼不用RGB呢?)--主要还是在达到最大压缩率的情况下，能够保证对人眼感知的失真度最小
## 『YUV』是什么？
- 颜色空间 “Y”表示明亮度（Luminance、Luma），“U”和“V”则是色度（Chrominance）、浓度（Chroma）。这里表示的是色彩空间的基，即类似XYZ坐标系的一种色标表示基准，也就是说每一种颜色可以通过三维向量<y^i^,u^i^,v^i^>来表示。与其类似的还有RGB颜色空间、HSV颜色空间等
- 采样率 读者可能听说过“YUV444”，“YUV422”，“YUV420”，到这里可能会纳闷：“YUV不是颜色空间吗？为什么后面还会跟着一串数字？” 因为当你看到YUV后面跟着一串数字的时候，『YUV』已经不再是颜色空间的基的含义了，而是意味着在原始『YUV流』上的采样。
在以前流媒体刚刚兴起时，还没有什么4G/5G，当时为了减小网络传输的带宽的压力，可谓做了种种努力。除了编码/压缩之外，YUV采样率也是一种。
444，422和420是三种『YUV』（在数字电路中指代YCbCr）的采样，三位数分别代表Y\U\V（数字电路中为Y\Cb\Cr，本段后同）通道的抽样比。所以可以理解，444是全采样；而422是对Y进行全采样，对U\V分别进行1/2均匀采样。有趣的问题来了，420难道是完全丢弃了V通道/分量数据嘛？答案是否定的。
首先，必须要搞明白一个问题，一帧图像是由一个个像素组成的矩形，譬如4x4的尺寸的图像，就是由16个像素点组成的。在平时接触的『RGB』图像中，每个像素必然至少由R\G\B这三个通道组成的（有的图像还有\alpha分量），每个分量的取值一般都是[0,255]，也就是[2^0，2^8]，因此经常说一个像素占用3字节（如果还有其他分量，比如RGBA，就另当别论）。『YUV』图像同理，它的每个像素是由Y\U\V组成的。
接下来，从整张图像宏观考虑采样问题。还是以4X4的图像为例，444的如下图2-1，这个是形象化成图像的样子，实际在机器内存储并不是这样，具体可以参见博客[《图像原始格式一探究竟》](https://www.cnblogs.com/tid-think/p/10616789.html)。
- 编码/存储格式 大家肯定还听说过YV12、YU12、NV12、NV21吧，看到这里是不是又纳闷：“后面的数字怎么变成2个了？而且前面的英文字母还变了？”
以上统称为『视频的存储格式』，也就是说，计算机是如何存储一帧视频的。
首先，『视频的存储格式』总分为两大类：『打包格式（packed）』和『平面格式（planar）』。前者又被称作『紧凑格式（packed）』。其实除此之外还有『半平面模式（Semi-Planar）』，估计是使用的比较少，因此在很多文章中常被忽略。
笔者很感兴趣，为什么会出现『打包格式』和『平面格式』两大派系 网上搜了很多资料也没找到原因，博客【音视频基础】：I420、YV12、NV12、NV21等常见的YUV420存储格式提到了需要约定存储格式，但也没提到为什么会分成这两种。要么就是派系之争，类似贝叶斯学派和频率学派；要么就是实际应用中逐渐衍生出这两大格式。时至今日，这两个格式还在被使用，因此对于多媒体开发者们都有必要了解。
『打包格式』是把Y\U\V分量交叉存储，『平面格式』则是把Y\U\V严格分开存储，『半平面模式』介于两者之间，Y分量分开存储，U\V交叉存储。
## 帧率（FPS）
『帧率』，FPS，全称Frames Per Second。指每秒传输的帧数，或者每秒显示的帧数，一般来说，『帧率』影响画面流畅度，且成正比：帧率越大，画面越流畅；帧率越小，画面越有跳动感。一个较权威的说法：
当视频帧率不低于24fps时，人眼才会觉得视频时连贯的，称为“视觉暂留”现象。
因此，才有说法：尽管『帧率』越高越流畅，但在很多实际应用场景中24fps就可以了。
## 分辨率（Resolution）
『分辨率』，也常被俗称为『图像的尺寸』或者『图像的大小』。指一帧图像包含的像素的多少，常见有1280x720（720P），1920X1080（1080P）等规格。『分辨率』影响图像大小，且与之成正比：『分辨率』越高，图像越大；反之，图像越小。
## 码率（BPS）
『码率』，BPS，全称Bits Per Second。指每秒传送的数据位数，常见单位KBPS（千位每秒）和MBPS（兆位每秒）。笔者认为这个概念真正要理解起来还是需要好好说明的，网上一说：“『码率』与体积成正比：码率越大，体积越大；码率越小，体积越小”；另一说：“『码率』越大，说明单位时间内取样率越大，数据流精度就越高，这样表现出来的的效果就是：视频画面更清晰画质更高”；还有说法是：”『码率』就是『失真度』“。但是笔者有一段时间就是不理解，每秒传输的数据越大，为什么必然就对应画面更清晰？还有体积怎么理解呢？且看下文”三者之间的关系“。
## I帧、P帧、B帧和IDR帧  都是帧，只是帧的数据不一样
- I帧，英文全写Intra Picture，又称帧内编码帧，俗称关键帧。一般来说I帧不需要依赖前后帧信息，可独立进行解码。有数据表明，仅I帧的压缩率，可以达到7，这里其实可以把I帧的压缩等同于单独压缩一幅图片。至于说I帧的压缩只压缩了空间上的冗余信息，放在后续编码相关的系列文章中会详述。【这里再挖一个坑，免得自己忘记了】
- P帧，英文全写predictive-frame，又称前向预测编码帧，也有帧间预测编码帧。顾名思义，P帧需要依赖前面的I帧或者P帧才能进行编解码，因为一般来说，P帧存储的是当前帧画面与前一帧（前一帧可能是I帧也可能是P帧）的差别，较专业的说法是压缩了时间冗余信息，或者说提取了运动特性。P帧的压缩率约在20左右，几乎所有的H264编码流都带有大量的P帧。
- B帧，英文全写bi-directional interpolatedprediction frame，又称 双向预测内插编码帧，简称双向预测编码帧。B帧非常特殊，它存储的是本帧与前后帧的差别，因此带有B帧的视频在解码时的逻辑会更复杂些，CPU开销会更大。因此，不是所有的视频都带有B帧，笔者目前还没有接触过带B帧的视频。【找到带B帧视频一定要珍藏起来好好研究！】不过，B帧的压缩率能够达到50甚至更高，在压缩率指标上还是很客观的。
- IDR帧，英文全写Instantaneous Decoding Refresh，翻译过来是即时解码刷新。听上去，这类帧并不是名词概念，倒像是个动词？IDR帧是一种特殊的I帧，它是为了服务于编解码而提出的概念，IDR帧的作用是立刻刷新,使错误不致传播,从IDR帧开始,重新算一个新的序列开始编码（摘自博客H264中I帧和IDR帧的区别）。
- I/P/B帧，并不是依据视频帧数据内部的元素的不同来区分的，从解码后的帧本身而言，它们没有任何区别。仅仅是在编码时，对帧处理的方式不同而已。

## GOP
英文全称Group Of Pictures，一般来说，指的就是两个I帧之间的间隔，严格来说，是两个IDR帧之间的间隔。笔者对GOP研究的不多，对于网上的说法：“GOP在一定程度上会影响视频画面质量 - 在码率相同的情况下，GOP越大，意味着P\B帧越多，也就更容易获取较好的图像质量”这个说法存疑。【这里留个坑待填】
## PTS、DTS
笔者是在对视频文件硬做解码的时候，发现实际解码输出的fps是硬解的能力上限，比如一个24fps的视频文件，在用硬件解码时，能够达到100+，当时接到一个需求是：“需要控制视频文件的解码率，让它和文件的fps保持一致”。后来查阅了大量的资料，进而了解了DTS和PTS的概念：
- DTS，英文全称Decoding Time Stamp，即解码时间戳，这个时间戳的意义在于告诉解码器该在什么时候解码这一帧的数据。
- PTS，英文全称Presentation Time Stamp，即显示时间戳，这个时间戳用来告诉播放器该在什么时候显示这一帧的数据
- 这个概念在做视音频同步的时候特别重要，尤其是PTS，目前常见的视音频同步的三种策略“同步到音频的PTS”、“同步到视频的PTS”和“同步到系统/外部时钟”，都是基于PTS完成的


参考 https://zhuanlan.zhihu.com/p/61747783